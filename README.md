# ðŸ“„ AI Knowledge Base Chatbot 

## Overview
This project is a **Retrieval-Augmented Generation (RAG) AI chatbot** that can answer questions over uploaded PDFs.  

- Upload multiple PDFs  
- Search across documents  
- Get answers grounded in the documents  
- Track conversation history per PDF 
- See sources for each answer

## Features
- âœ… Upload PDFs and manage multiple documents  
- âœ… Ask questions about uploaded PDFs  
- âœ… Multi-PDF chat memory   
- âœ… Source citations for each answer  
- âœ… Fully deployable with Docker  

## Tech Stack
- **LLM:** Ollama LLaMA 3
- **Framework:** LangChain
- **Embeddings:** HuggingFace Sentence Transformers
- **Vector DB:** Chroma
- **Backend:** FastAPI
- **Frontend:** Streamlit
- **Deployment:** Docker

## Project Structure
```
rag-chatbot/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ backend.py
â”‚ â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ frontend.py
â”‚ â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ uploads/ # Folder for uploaded PDFs (auto-created)
â”œâ”€â”€ backend.log # Generated by logging (auto-created)
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

## Setup Locally

### Backend
```bash
cd backend
pip install -r requirements.txt
uvicorn backend:app --reload
```

### Frontend
``` bash
cd frontend
pip install -r requirements.txt
streamlit run frontend.py
```

### Docker
``` bash
docker build -t rag-chatbot .
docker run -p 8000:8000 -p 8501:8501 rag-chatbot
```

## Usage

1. Open the frontend in your browser
2. Upload a PDF (or multiple PDFs)
3. Select a PDF from the sidebar
4. Ask questions; answers appear with chat history visible
5. Switch PDFs anytime using the sidebar
6. See sources for each answer

> **Note:** Chat history is saved per PDF while the session is running. Backend logs are saved in `backend.log`.


---
## Demo: 

<img width="1671" height="837" alt="sample" src="https://github.com/user-attachments/assets/895ed56b-4f54-427e-88bc-6d56d963e353" />

